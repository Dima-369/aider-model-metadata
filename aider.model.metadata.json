{
  "openai/claude-3.5-sonnet": {
    "max_tokens": 200000,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0,
    "output_cost_per_token": 0,
    "litellm_provider": "openai",
    "mode": "chat"
  },
  "openai/command-a-03-2025": {
    "max_tokens": 256000,
    "max_input_tokens": 256000,
    "max_output_tokens": 8096,
    "input_cost_per_token": 0,
    "output_cost_per_token": 0,
    "litellm_provider": "openai",
    "mode": "chat"
  },
  "openai/openai-large": {
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.00000060,
        "input_cost_per_token_batches": 0.000000075,
        "output_cost_per_token_batches": 0.00000030,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true
    }
}
